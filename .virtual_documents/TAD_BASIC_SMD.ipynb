import json
import os
import random

import sklearn
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
from tensorflow import keras
from tensorflow.keras import layers

# from sklearn.metrics import confusion_matrix

os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"] = "1"
os.environ["TF_FORCE_GPU_ALLOW_GROWTH"] = "true"


train_url = "./datasets/SMD/train/"
test_url = "./datasets/SMD/test/"
machine_label = {1: 8, 2: 9, 3: 11}
train_data = []
test_data = []
for i, nums in machine_label.items():
    train = []
    test = []
    for j in range(1, nums + 1):
        file_name = f"machine-{i}-{j}.csv"
        df_train = pd.read_csv(
            os.path.join(train_url, file_name), parse_dates=True, index_col="timestamp"
        )
        df_test = pd.read_csv(
            os.path.join(test_url, file_name), parse_dates=True, index_col="timestamp"
        )
        train.append(df_train)
        test.append(df_test)
    train_data.append(train)
    test_data.append(test)


fig, ax = plt.subplots()
train_data[machine][idx].plot(legend=False, ax=ax, subplots=True, layout=(10, 4), sharex=True)
plt.show()


# Normalize and save the mean and std we get,
# for normalizing test data.
# Since model is too simple, so we will use only few featrues for learning.
num_of_features = 38
data_for_train = train_data[machine][idx].fillna(method='ffill').iloc[:, :num_of_features]

# training_mean = data_for_train.mean()
# training_std = data_for_train.std()
training_mean = 0
training_std = 1
df_training_value = (data_for_train - training_mean) / training_std


data_for_train.mean()
data_for_train.std()
norm = (data_for_train - data_for_train.mean()) / data_for_train.std()
norm.mean()


# Increase TIME_STEPS: high recall, low precision
# Decrease TIME_STEPS: low recall, high precision
TIME_STEPS = 500


# Generated training sequences for use in the model.
def create_sequences(values, time_steps=TIME_STEPS):
    output = []
    for i in range(len(values) - time_steps + 1):
        output.append(values[i : (i + time_steps)])
    return np.stack(output)


x_train = create_sequences(df_training_value.values)
print("Training input shape: ", x_train.shape)


model = keras.Sequential(
    [
        layers.InputLayer((x_train.shape[1], x_train.shape[2])),
        layers.Conv1D(filters=32, kernel_size=7, padding="same", strides=2, activation="relu"),
        layers.Dropout(rate=0.2),
        layers.Conv1D(filters=16, kernel_size=7, padding="same", strides=2, activation="relu"),
        layers.Conv1DTranspose(
            filters=16, kernel_size=7, padding="same", strides=2, activation="relu"
        ),
        layers.Dropout(rate=0.2),
        layers.Conv1DTranspose(
            filters=32, kernel_size=7, padding="same", strides=2, activation="relu"
        ),
        layers.Conv1DTranspose(filters=x_train.shape[2], kernel_size=7, padding="same"),
    ]
)
model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss="mse")
model.summary()


history = model.fit(
    x_train,
    x_train,
    epochs=50,
    batch_size=128,
    validation_split=0.1,
    callbacks=[keras.callbacks.EarlyStopping(monitor="val_loss", patience=5, mode="min")],
)


plt.plot(history.history["loss"], label="Training Loss")
plt.plot(history.history["val_loss"], label="Validation Loss")
plt.legend()
plt.show()


# Get train MAE loss.
x_train_pred = model.predict(x_train)
train_mae_loss = np.mean(np.abs(x_train_pred - x_train), axis=1)

# Get reconstruction loss threshold.
threshold = np.max(train_mae_loss, axis=0)
print("Reconstruction error threshold: ", threshold)


data_for_test = test_data[machine][idx]

df_test_value = (data_for_test - training_mean) / training_std

# Create sequences from test values.
x_test = create_sequences(df_test_value.values)
print("Test input shape: ", x_test.shape)

# Get test MAE loss.
x_test_pred = model.predict(x_test)
test_mae_loss = np.mean(np.abs(x_test_pred - x_test), axis=1)
# test_mae_loss = test_mae_loss.reshape((-1))

# Detect all the samples which are anomalies.
print(test_mae_loss.shape)
anomalies = np.sum(test_mae_loss, axis=1) > np.sum(threshold)
print("Number of anomaly samples: ", np.sum(anomalies))
print("Indices of anomaly samples: ", np.where(anomalies))


# data i is an anomaly if samples [(i - timesteps + 1) to (i)] are anomalies
anomalous_data_indices = []
for data_idx in range(TIME_STEPS - 1, len(df_test_value) - TIME_STEPS + 1):
    if np.any(anomalies[data_idx - TIME_STEPS + 1 : data_idx]):
        anomalous_data_indices.append(data_idx)


df_subset = test_data[machine][idx]["feature_1"].iloc[anomalous_data_indices]
fig, ax = plt.subplots()
test_data[machine][idx]["feature_1"].plot(legend=False, ax=ax)
df_subset.plot(legend=False, ax=ax, color="r")
plt.show()


test_pred = np.zeros(len(test_data[machine][idx]))
test_label = test_data[machine][idx]["label"]
test_pred[anomalous_data_indices] = 1

accuracy = (np.sum(test_pred == test_label)) / len(test_label) * 100
precision = (np.sum(test_pred * test_label)) / np.sum(test_pred) * 100
recall = (np.sum(test_pred * test_label)) / np.sum(test_label) * 100

print(f"accuracy: {accuracy:.2f}%")
print(f"precision: {precision:.2f}%")
print(f"recall: {recall:.2f}%")


from sklearn.metrics import classification_report
print(classification_report(test_label, test_pred))
